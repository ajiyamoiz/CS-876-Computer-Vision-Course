{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9dSxofuVCRm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QkREVzvnIAM"
      },
      "source": [
        "# OpenCV\n",
        "\n",
        "## Size and Resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6nQHuu4GnNHy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg', cv2.IMREAD_UNCHANGED)\n",
        "print('Original Dimensions : ',img.shape)\n",
        "cv2_imshow(img)\n",
        "\n",
        "scale_percent = 200 # percent of original size\n",
        "width = int(img.shape[1] * scale_percent / 100)\n",
        "height = int(img.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "\n",
        "# resize image\n",
        "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "print('Resized Dimensions : ', resized.shape)\n",
        "cv2_imshow(resized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdYfTmBsmfuw"
      },
      "source": [
        "## Color Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdyBfweoUy76"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# OpenCV number of flags\n",
        "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
        "len(flags)\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg')\n",
        "# BGR to RGB color\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Color Segmentation\n",
        "from matplotlib.colors import hsv_to_rgb\n",
        "\n",
        "hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "light_white = (0, 0, 200)\n",
        "dark_white = (145, 60, 255)\n",
        "\n",
        "lw_square = np.full((10, 10, 3), light_white, dtype=np.uint8) / 255.0\n",
        "dw_square = np.full((10, 10, 3), dark_white, dtype=np.uint8) / 255.0\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(hsv_to_rgb(lw_square))\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(hsv_to_rgb(dw_square))\n",
        "\n",
        "mask_white = cv2.inRange(hsv_img, light_white, dark_white)\n",
        "result_white = cv2.bitwise_and(img, img, mask=mask_white)\n",
        "\n",
        "#plt.imshow(mask_white, cmap=\"gray\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(result_white)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oue7GxzTnNps"
      },
      "source": [
        "## Image Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIfV6wianZe3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg')\n",
        "\n",
        "# 2D Convolution\n",
        "kernel = np.ones((5,5),np.float32)/8\n",
        "dst = cv2.filter2D(img,-1,kernel)\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# Blur filter\n",
        "blurImg = cv2.blur(img,(10,10))\n",
        "cv2_imshow(blurImg)\n",
        "\n",
        "# Gaussian Filter\n",
        "Gblur = cv2.GaussianBlur(img,(5,5),0)\n",
        "cv2_imshow(Gblur)\n",
        "\n",
        "# Median Blur\n",
        "median = cv2.medianBlur(img,5)\n",
        "cv2_imshow(median)\n",
        "\n",
        "# Bilateral Blur\n",
        "Bblur = cv2.bilateralFilter(img,9,75,75)\n",
        "cv2_imshow(Bblur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAglaaWQmo75"
      },
      "source": [
        "## Edge Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGzOK4YgnHHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy import ndimage\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gaussian = cv2.GaussianBlur(gray,(5,5),0)\n",
        "\n",
        "# Canny\n",
        "edges = cv2.Canny(img,100,200)\n",
        "plt.imshow(edges,cmap = 'gray')\n",
        "plt.title('Canny'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# Laplacian\n",
        "laplacian = cv2.Laplacian(img_gaussian,cv2.CV_64F)\n",
        "plt.imshow(laplacian,cmap = 'gray')\n",
        "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# Sobel\n",
        "sobelx = cv2.Sobel(img_gaussian,cv2.CV_64F,1,0,ksize=5)  # x\n",
        "sobely = cv2.Sobel(img_gaussian,cv2.CV_64F,0,1,ksize=5)  # y\n",
        "sobel = sobelx + sobely\n",
        "\n",
        "plt.subplot(1,3,1),plt.imshow(sobelx,cmap = 'gray')\n",
        "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(1,3,2),plt.imshow(sobely,cmap = 'gray')\n",
        "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(1,3,3),plt.imshow(sobel,cmap = 'gray')\n",
        "plt.title('Sobel'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# Prewitt\n",
        "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
        "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
        "img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
        "\n",
        "plt.subplot(1,3,1),plt.imshow(img_prewittx,cmap = 'gray')\n",
        "plt.title('Prewitt X'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(1,3,2),plt.imshow(img_prewitty,cmap = 'gray')\n",
        "plt.title('Prewitt Y'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(1,3,3),plt.imshow(img_prewittx + img_prewitty,cmap = 'gray')\n",
        "plt.title('Prewitt'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# Roberts\n",
        "roberts_cross_v = np.array( [[1, 0 ], [0,-1 ]] )\n",
        "roberts_cross_h = np.array( [[ 0, 1 ], [ -1, 0 ]] )\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg',0).astype('float64')/255.0\n",
        "vertical = ndimage.convolve( img, roberts_cross_v )\n",
        "horizontal = ndimage.convolve( img, roberts_cross_h )\n",
        "edged_img = np.sqrt(np.square(horizontal) + np.square(vertical))*255\n",
        "cv2_imshow(edged_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DqGlG8Rn7yH"
      },
      "source": [
        "## Sharpening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXuZnIWYn_-E"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Picture1.jpg', flags=cv2.IMREAD_COLOR)\n",
        "kernel = np.array([[0, -1, 0],\n",
        "                   [-1, 5,-1],\n",
        "                   [0, -1, 0]])\n",
        "image_sharp = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
        "cv2_imshow(image_sharp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViNAV1NLpOFs"
      },
      "source": [
        "# MNIST Dataset\n",
        "\n",
        "* OpenCV Library\n",
        "* Download MNIST Data in CSV format from the link provided: https://www.kaggle.com/datasets/oddrationale/mnist-in-csv?datasetId=27352&searchQuery=download\n",
        "* Reshape the images to 28x28\n",
        "* Print them and check label for each\n",
        "* Compare MSE among the images of same classes and different classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNedwOxCHGGo"
      },
      "outputs": [],
      "source": [
        "#https://www.youtube.com/watch?v=GyyrnOHwe2E\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "d0 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Computer Vision/mnist_train.csv')\n",
        "#print(d0.head())\n",
        "l = d0['label']\n",
        "d = d0.drop(\"label\", axis=1)\n",
        "print(d.shape)\n",
        "print(l.shape)\n",
        "\n",
        "# Print and check label\n",
        "plt.figure(figsize=(7,7))\n",
        "idx = 100\n",
        "grid_data = d.iloc[idx].to_numpy().reshape(28,28)\n",
        "plt.imshow(grid_data, interpolation=\"none\", cmap=\"gray\")\n",
        "plt.show()\n",
        "print(l[idx])\n",
        "\n",
        "# Group by class\n",
        "by_class = d0.groupby('label')\n",
        "print(by_class.get_group(5))\n",
        "\n",
        "# Mean Squared Error\n",
        "a = 100\n",
        "b = 0\n",
        "Y_true = l[a]\n",
        "plt.subplot(1,2,1), plt.imshow(d.iloc[a].to_numpy().reshape(28,28), cmap=\"gray\")\n",
        "Y_pred = l[b]\n",
        "plt.subplot(1,2,2), plt.imshow(d.iloc[b].to_numpy().reshape(28,28), cmap=\"gray\")\n",
        "MSE = np.square(np.subtract(Y_true,Y_pred)).mean()\n",
        "print(MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqld-B1RpQ59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def get_data(filename):\n",
        "    with open(filename) as data_file:\n",
        "        headers = data_file.readline()\n",
        "        a = np.loadtxt(data_file, delimiter=',')\n",
        "        labels = a[:,0]\n",
        "        a = a[:,1:]\n",
        "        images = np.reshape(a, (-1, 28, 28))\n",
        "        images = images.astype(float)\n",
        "    return images, labels\n",
        "\n",
        "path_sample_csv = f\"/content/drive/MyDrive/Colab Notebooks/Computer Vision/mnist_train.csv\"\n",
        "training_images, training_labels = get_data3(path_sample_csv)\n",
        "print(\"training_images.shape: \", training_images.shape)\n",
        "print(\"training_labels.shape: \", training_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS_73czWpI6i"
      },
      "source": [
        "## Flatten Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDAxcA4QpLWS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "#flatten the array\n",
        "print('flattening a...')\n",
        "print(a.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvcSQVo9pEIW"
      },
      "source": [
        "## Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPbxM1zSpIXD"
      },
      "outputs": [],
      "source": [
        "#from numpy.ma.core import flatten_structured_array\n",
        "import numpy as np\n",
        "\n",
        "# Given values\n",
        "Y_true = [1,1,2,2,4]  # Y_true = Y (original values)\n",
        "\n",
        "# Calculated values\n",
        "Y_pred = [0.6,1.29,1.99,2.69,3.4]  # Y_pred = Y'\n",
        "\n",
        "# Mean Squared Error\n",
        "MSE = np.square(np.subtract(Y_true,Y_pred)).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd8VvRqZ3Y1k"
      },
      "source": [
        "* Implement a single neuron for single MNIST image with label\n",
        "* Compute p\n",
        "* Compare p with t\n",
        "* Calculate Error between p and t\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ_BUvNUZQqS"
      },
      "outputs": [],
      "source": [
        "from numpy import exp, array, random, dot, tanh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "d0 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Computer Vision/mnist_train.csv')\n",
        "#print(d0.head())\n",
        "l = d0['label']\n",
        "d = d0.drop(\"label\", axis=1)\n",
        "print(d.shape)\n",
        "print(l.shape)\n",
        "\n",
        "# Network with single neuron\n",
        "class NeuralNetwork():\n",
        "    def __init__(self):\n",
        "        # Using seed to make sure it'll generate same weights in every run\n",
        "        random.seed(1)\n",
        "        # 784x1 Weight matrix\n",
        "        self.weight_matrix = 2 * random.random((784,22361)) - 1\n",
        "\n",
        "    # tanh as activation function\n",
        "    def tanh(self, x):\n",
        "        return tanh(x)\n",
        "    # derivative of tanh function needed to calculate the gradients.\n",
        "    def tanh_derivative(self, x):\n",
        "        return 1.0 - tanh(x) ** 2\n",
        "\n",
        "    # forward propagation\n",
        "    def forward_propagation(self, inputs):\n",
        "        return self.tanh(dot(inputs, self.weight_matrix))\n",
        "    # training the neural network.\n",
        "    def train(self, train_inputs, train_outputs, num_train_iterations):\n",
        "        # Number of iterations we want to perform for this set of input.\n",
        "        for iteration in range(num_train_iterations):\n",
        "            output = self.forward_propagation(train_inputs)\n",
        "            # Calculate the error in the output.\n",
        "            error = train_outputs - output\n",
        "            # multiply the error by input and then by gradient of tanh function to calculate the adjustment needs to be made in weights\n",
        "            adjustment = dot(train_inputs.T, error * self.tanh_derivative(output))\n",
        "            # Adjust the weight matrix\n",
        "            self.weight_matrix += adjustment\n",
        "\n",
        "# Driver Code\n",
        "if __name__ == \"__main__\":\n",
        "    neural_network = NeuralNetwork()\n",
        "    print ('Random weights at the start of training')\n",
        "    print (neural_network.weight_matrix)\n",
        "    #train_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "    #train_outputs = array([[0, 1, 1, 0]]).T\n",
        "    train_inputs = np.array(d)\n",
        "    train_outputs = np.array(l).T\n",
        "    neural_network.train(train_inputs, train_outputs, 10000)\n",
        "    print ('New weights after training')\n",
        "    print (neural_network.weight_matrix)\n",
        "\n",
        "    # Test the neural network with a new situation\n",
        "    di = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Computer Vision/mnist_test.csv')\n",
        "    k = di['label 0']\n",
        "    m = di.drop(\"label 0\", axis=1)\n",
        "    print(k.shape)\n",
        "    print(m.shape)\n",
        "\n",
        "    print (\"Testing network on new examples ->\")\n",
        "    print (neural_network.forward_propagation(np.array(m[idx])))\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    idx = 100\n",
        "    grid_data = m.iloc[idx].to_numpy().reshape(28,28)\n",
        "    plt.imshow(grid_data, interpolation=\"none\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    print(m[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRACPP3qlZ9D"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/Computer Vision/mnist_train.csv\")\n",
        "array.img = np.as_array(img)\n",
        "flattened.array.img = np.flatten(array.img)\n",
        "weights = np.random(784,1)\n",
        "np.matmal(flattened.array.np*weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsaitkDz4bNv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "image_index = 7777 # You may select anything up to 60,000\n",
        "print(y_train[image_index]) # The label is 8\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])\n",
        "\n",
        "# Importing the required Keras modules containing model and layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=10)\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "image_index = 4444\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print(pred.argmax())\n",
        "\n",
        "# Mean Squared Error\n",
        "MSE = np.square(np.subtract(x_test,y_test)).mean()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jlPLolEzwRvt6vFed3FN7ob7cauYeSEj",
      "authorship_tag": "ABX9TyPQvPuBtpVFNXrI7VnHlLJV"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}